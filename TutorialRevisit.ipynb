{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Tutorial Revisit\n",
    "\n",
    "In this Notebook the Tutorials will be revisited and described in a few paragraphs\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tutorial 1\n",
    "\n",
    "In the first tutorial, we get a glimpse of what a neural network actually is, and what some fundamental principles mean - namely backpropagation, an activation function, the loss and how to implement a simple neural network with Tensorflow. All that is shown with the 'hello world' of deep learning - the MNIST dataset.\n",
    "\n",
    "### Backpropagation\n",
    "\n",
    "Backpropagation is a fundamental part of fitting a neural network, to get the network to learn properly, we have to look at our expected result and the result the network has given. We then compare these and go from last to first layer to change the weights and biases at each node, so our Loss gets minimized.\n",
    "\n",
    "### Activation Function\n",
    "\n",
    "The activation function is a mathematical function that is applied to the output of a neuron in a neural network. The purpose of the activation function is to introduce nonlinearity into the network, allowing the model to learn more complex relationships between the input features and the output. There are four widely used ones: Sigmoid, Tanh, ReLU and Leaky ReLU. Each activation function has its own properties and is suitable for different types of tasks.\n",
    "### Loss function\n",
    "\n",
    "To determine our loss, we need a loss function: It is a scalar value which we get from comparing the predicted outcome with the desired output. The loss function we use in the first example is the least squares approximation.\n",
    "### Implementation with Tensorflow\n",
    "\n",
    "With Tensorflow, a library provided by Google to make development of neural networks easier and focus on deeper topics, such as diving into different architectures and adding more layers.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tutorial 2\n",
    "The second Tutorial is all about reusing a pretrained model for the classification of pictures of cats or dogs. We use a pretrained model as a feature extractor and build our own model onto this output to get a working cats-and-dogs-classification-model.\n",
    "\n",
    "### Preparing the data\n",
    "\n",
    "### Feature Extraction\n",
    "\n",
    "### Modeling and training for our output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tutorial 3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*so long and thanks for all the fish*"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
